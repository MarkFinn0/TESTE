{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1443276f",
   "metadata": {},
   "source": [
    "# 1.Pré tratamento dos dados para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "001adca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2993c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"Cuspidão\\Completao.csv\",delimiter=';',encoding=\"latin-1\",decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e52f9",
   "metadata": {},
   "source": [
    "# Criar variáveis gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8db85fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um variável com o nome de todos os setores do dataset e cria uma flag para se tem somente essa empresa no setor\n",
    "ListofCompanies=df.drop_duplicates(subset=['SETOR_ATIV','Nome Empresa'])\n",
    "ListofCompanies=ListofCompanies['SETOR_ATIV'].value_counts()\n",
    "ListofCompanies=pd.DataFrame(ListofCompanies)\n",
    "Listof1Companies=ListofCompanies[ListofCompanies['SETOR_ATIV']<4]\n",
    "ListofCompanies=ListofCompanies[ListofCompanies['SETOR_ATIV']>=4]\n",
    "ListofCompanies['Flag1Company']=0\n",
    "Listof1Companies['Flag1Company']=1\n",
    "ListofCompanies=pd.concat([ListofCompanies,Listof1Companies])\n",
    "ListofCompanies['SETOR_ATIV']=ListofCompanies.index\n",
    "\n",
    "#Cria Variáveis de Cuspir\n",
    "DF_Polyline=pd.DataFrame()\n",
    "DF_Cuspidao=pd.DataFrame()\n",
    "DF_Cuspidao2=pd.DataFrame()\n",
    "DF_Cuspidao_BAU=pd.DataFrame()\n",
    "DF_Cuspidao_RESTO=pd.DataFrame()\n",
    "df_produ_kmeans_REST_ALL=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cfec9",
   "metadata": {},
   "source": [
    "# Pré tratar dados para modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45d57da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criar ano e mes\n",
    "df['Ano']=df['DT_REFER'].apply(str).str[0:4]\n",
    "df['Mes']=df['DT_REFER'].apply(str).str[5:7]\n",
    "#Transformar colunas negativas em positivas\n",
    "df['Passivo Circulante']=df['Passivo Circulante']*-1\n",
    "df['Passivo Total']=df['Passivo Total']*-1\n",
    "#Coloca a Flag de 1 company no dataset central\n",
    "df1 = pd.merge( ListofCompanies,df, left_on='SETOR_ATIV', right_on='SETOR_ATIV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bed0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_produ=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69a55555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma as relações de indicadores para clusterizar em numeros, para o for andar de lado.\n",
    "df_produ[14]=df_produ['Ativo Circulante'].clip(lower=0)\n",
    "df_produ[13]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[12]=df_produ['Passivo Circulante'].clip(upper=0)\n",
    "df_produ[11]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[10]=df_produ['Passivo Total'].clip(upper=0)\n",
    "df_produ[9]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[8]=df_produ['Ativo Total'].clip(lower=0)\n",
    "df_produ[7]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[6]=df_produ['Reservas de Lucro'].clip(lower=0)\n",
    "df_produ[5]=df_produ['Receita'].clip(lower=0)\n",
    "df_produ[4]=df_produ['Receita'].clip(lower=0)\n",
    "df_produ[3]=df_produ['Patrimônio Líquido'].clip(lower=0)\n",
    "df_produ[2]=df_produ['Receita'].clip(lower=0)\n",
    "df_produ[1]=df_produ['Lucro/Prejuízo do Período'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ddd54",
   "metadata": {},
   "source": [
    "# Clusterizar as empresas com dados realizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8160b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provisorio=df_produ\n",
    "df_provisorio=df_provisorio[['Nome Empresa',\n",
    "                             'Ticker',\n",
    "                             'SETOR_ATIV',\n",
    "                             'Flag1Company',\n",
    "                             'DT_REFER',\n",
    "                             'Ano',\n",
    "                             'Mes',\n",
    "                             1,2,3,4,5,6,7,8,9,10,11,12,13,14]]\n",
    "#BAU KMEANS\n",
    "for y in range(1,13):\n",
    "    for x in ListofCompanies.index.values:\n",
    "        if y==1:\n",
    "            y1=1\n",
    "            y2=2\n",
    "        else:\n",
    "            y1=y+1\n",
    "            y2=y+2\n",
    "        #filtra o setor\n",
    "        df_produ_kmeans=df_provisorio[(df_provisorio['SETOR_ATIV']==x)&(df_provisorio['Flag1Company']==0)].reset_index(drop=True)\n",
    "      \n",
    "        Tcks_count=df_produ_kmeans.drop_duplicates(subset=['Ticker','DT_REFER'])\n",
    "        Tcks_count=Tcks_count['DT_REFER'].value_counts()\n",
    "        Tcks_count_mean=Tcks_count.mean()\n",
    "        Tcks_count=pd.DataFrame(Tcks_count)\n",
    "        ListOFTRI=Tcks_count[Tcks_count['DT_REFER']>=Tcks_count_mean]\n",
    "        ListOFTRI['DATE']=ListOFTRI.index\n",
    "        AnoMAX=ListOFTRI['DATE'].apply(str).str[0:4].max()\n",
    "        MesMAX=ListOFTRI['DATE'].apply(str).str[5:7].max()\n",
    "\n",
    "        #Filtrar ano e mês (ultimo tri de cada setor)\n",
    "        df_produ_kmeans=df_produ_kmeans[(df_produ_kmeans[\"Ano\"]==AnoMAX)&(df_produ_kmeans[\"Mes\"]==MesMAX)].reset_index(drop=True)      \n",
    "        #Clusteriza as empresas com valores negativos como 0 (ruim)\n",
    "        df_produ_kmeans_REST_NO=df_produ_kmeans[(df_produ_kmeans[y1]==0)|(df_produ_kmeans[y2]==0)].reset_index(drop=True)\n",
    "        df_produ_kmeans_REST_NO[f\"{y1}{y2} Cluster\"]=0\n",
    "        #Separa as empresas que são elegíveis a escalabilidade e a clusterização\n",
    "        df_produ_kmeans=df_produ_kmeans[(df_produ_kmeans[y1]!=0)&(df_produ_kmeans[y2]!=0)].reset_index(drop=True)\n",
    "        df_produ_kmeans=df_produ_kmeans.sort_values(by=[y1,y2]).reset_index(drop=True)\n",
    "        \n",
    "        #se tiver mais de 1 amostra (empresa)\n",
    "        if len(df_produ_kmeans)>=2:\n",
    "            #FAÇO A ESCALABILIDADE COM STANDARD\n",
    "            scaler = StandardScaler() \n",
    "            pca = PCA(n_components = 2) \n",
    "            features= df_produ_kmeans[[y1,y2]]\n",
    "            scaled_df = scaler.fit_transform(features) \n",
    "            normalized_df = normalize(scaled_df) \n",
    "            normalized_df = pd.DataFrame(normalized_df)\n",
    "            #E DEPOIS REDUZO AS DIMENSÕES E CORRELAÇÕES COM O PCA\n",
    "            X_principal = pca.fit_transform(normalized_df) \n",
    "            features = pd.DataFrame(X_principal) \n",
    "            features.columns = ['P1', 'P2']\n",
    "            c=3\n",
    "            if len(features)<3:\n",
    "                c=len(features)\n",
    "                \n",
    "            #DOU UM FIT NO KMEANS\n",
    "            kmeans = KMeans(n_clusters=c, init='random',\n",
    "                        n_init=10,\n",
    "                        max_iter=300,random_state=0)\n",
    "            kmeans.fit(features)\n",
    "            #DPS EU FAÇO A CLUSTERIZAÇÃO\n",
    "            d = KMeans(n_clusters=c, init='random',\n",
    "                        n_init=10,\n",
    "                        max_iter=300,random_state=0).fit_predict(features)\n",
    "            df_produ_kmeans[f\"{y1}{y2} Cluster\"]=d\n",
    "            DF_Cuspidao2=pd.concat([df_produ_kmeans,df_produ_kmeans_REST_NO]).reset_index(drop=True)\n",
    "            DF_Cuspidao_BAU=pd.concat([DF_Cuspidao2,DF_Cuspidao_BAU]).reset_index(drop=True)\n",
    "        else:\n",
    "            DF_Cuspidao2=pd.concat([df_produ_kmeans,df_produ_kmeans_REST_NO]).reset_index(drop=True)\n",
    "            DF_Cuspidao_BAU=pd.concat([DF_Cuspidao2,DF_Cuspidao_BAU]).reset_index(drop=True)\n",
    "    df_provisorio=DF_Cuspidao_BAU\n",
    "    DF_Cuspidao2=pd.DataFrame()\n",
    "    DF_Cuspidao_BAU=pd.DataFrame()\n",
    "    \n",
    "DF_Cuspidao_BAU=df_provisorio\n",
    "DF_Cuspidao=pd.DataFrame()\n",
    "df_provisorio=df_produ\n",
    "df_provisorio=df_provisorio[['Nome Empresa',\n",
    "                             'Ticker',\n",
    "                             'SETOR_ATIV',\n",
    "                             'Flag1Company',\n",
    "                             'DT_REFER',\n",
    "                             'Ano',\n",
    "                             'Mes',\n",
    "                             1,2,3,4,5,6,7,8,9,10,11,12,13,14]]\n",
    "#REJEITADOS KMEANS\n",
    "for y in range(1,13):\n",
    "    if y==1:\n",
    "        y1=1\n",
    "        y2=2\n",
    "    else:\n",
    "        y1=y+1\n",
    "        y2=y+2\n",
    "    #filtra o setor\n",
    "    df_produ_kmeans=df_provisorio[(df_provisorio['Flag1Company']==1)].reset_index(drop=True)\n",
    "    Tcks_count=df_produ_kmeans.drop_duplicates(subset=['Ticker','DT_REFER'])\n",
    "    Tcks_count=Tcks_count['DT_REFER'].value_counts()\n",
    "    Tcks_count_mean=Tcks_count.mean()\n",
    "    Tcks_count=pd.DataFrame(Tcks_count)\n",
    "    ListOFTRI=Tcks_count[Tcks_count['DT_REFER']>=Tcks_count_mean]\n",
    "    ListOFTRI['DATE']=ListOFTRI.index\n",
    "    AnoMAX=ListOFTRI['DATE'].apply(str).str[0:4].max()\n",
    "    MesMAX=ListOFTRI['DATE'].apply(str).str[5:7].max()\n",
    "    #Filtrar ano e mês (ultimo tri de cada setor)\n",
    "    df_produ_kmeans=df_produ_kmeans[(df_produ_kmeans[\"Ano\"]==AnoMAX)&(df_produ_kmeans[\"Mes\"]==MesMAX)].reset_index(drop=True)\n",
    "    #Clusteriza as empresas com valores negativos como 0 (ruim)\n",
    "    df_produ_kmeans_REST_NO=df_produ_kmeans[(df_produ_kmeans[y1]==0)|(df_produ_kmeans[y2]==0)].reset_index(drop=True)\n",
    "    df_produ_kmeans_REST_NO[f\"{y1}{y2} Cluster\"]=0\n",
    "    #Separa as empresas que são elegíveis a escalabilidade e a clusterização\n",
    "    df_produ_kmeans=df_produ_kmeans[(df_produ_kmeans[y1]!=0)&(df_produ_kmeans[y2]!=0)].reset_index(drop=True)\n",
    "    df_produ_kmeans=df_produ_kmeans.sort_values(by=[y1,y2]).reset_index(drop=True)\n",
    "    #se tiver mais de 1 amostra (empresa)\n",
    "    if len(df_produ_kmeans)>=2:\n",
    "        #FAÇO A ESCALABILIDADE COM STANDARD\n",
    "        scaler = StandardScaler() \n",
    "        pca = PCA(n_components = 2) \n",
    "        features= df_produ_kmeans[[y1,y2]]\n",
    "        scaled_df = scaler.fit_transform(features) \n",
    "        normalized_df = normalize(scaled_df) \n",
    "        normalized_df = pd.DataFrame(normalized_df)\n",
    "        #E DEPOIS REDUZO AS DIMENSÕES E CORRELAÇÕES COM O PCA\n",
    "        X_principal = pca.fit_transform(normalized_df) \n",
    "        features = pd.DataFrame(X_principal) \n",
    "        features.columns = ['P1', 'P2']\n",
    "        c=3\n",
    "        if len(features)<3:\n",
    "            c=len(features)\n",
    "        #DOU UM FIT NO KMEANS\n",
    "        kmeans = KMeans(n_clusters=c, init='random',\n",
    "                    n_init=10,\n",
    "                    max_iter=300,random_state=0)\n",
    "        kmeans.fit(features)\n",
    "        #DPS EU FAÇO A CLUSTERIZAÇÃO\n",
    "        d = KMeans(n_clusters=c, init='random',\n",
    "                    n_init=10,\n",
    "                    max_iter=300,random_state=0).fit_predict(features)\n",
    "        df_produ_kmeans[f\"{y1}{y2} Cluster\"]=d\n",
    "        DF_Cuspidao2=pd.concat([df_produ_kmeans,df_produ_kmeans_REST_NO]).reset_index(drop=True)\n",
    "        DF_Cuspidao_RESTO=pd.concat([DF_Cuspidao2,DF_Cuspidao_RESTO]).reset_index(drop=True)\n",
    "    else:\n",
    "        DF_Cuspidao2=pd.concat([df_produ_kmeans,df_produ_kmeans_REST_NO]).reset_index(drop=True)\n",
    "        DF_Cuspidao_RESTO=pd.concat([DF_Cuspidao2,DF_Cuspidao_RESTO]).reset_index(drop=True)\n",
    "    df_provisorio=DF_Cuspidao_RESTO\n",
    "    DF_Cuspidao2=pd.DataFrame()\n",
    "    DF_Cuspidao_RESTO=pd.DataFrame()\n",
    "DF_kmeans=pd.concat([DF_Cuspidao_BAU,df_provisorio]).reset_index(drop=True)\n",
    "DF_kmeans[\"Dados\"]=\"Realizado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b3a891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_kmeans=DF_kmeans[['Nome Empresa','Ticker','SETOR_ATIV','DT_REFER',\"Dados\",\n",
    "             1,2,3,4,5,6,7,8,9,10,11,12,13,14,\n",
    "            '12 Cluster',\n",
    "            '34 Cluster',\n",
    "            '56 Cluster',\n",
    "            '78 Cluster',\n",
    "            '910 Cluster',\n",
    "            '1112 Cluster',\n",
    "            '1314 Cluster',\n",
    "             ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8d4dc",
   "metadata": {},
   "source": [
    "# Prever os próximos 4 tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38755ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separo os indicadores que eu quero prever\n",
    "df_produ[11]=df_produ['Obrigações Fiscais']\n",
    "df_produ[10]=df_produ['Obrigações Sociais e Trabalhistas']\n",
    "df_produ[9]=df_produ['Contas a Receber']\n",
    "df_produ[8]=df_produ['Ativo Circulante']\n",
    "df_produ[7]=df_produ['Passivo Circulante']\n",
    "df_produ[6]=df_produ['Passivo Total']\n",
    "df_produ[5]=df_produ['Ativo Total']\n",
    "df_produ[4]=df_produ['Reservas de Lucro']\n",
    "df_produ[3]=df_produ['Patrimônio Líquido']\n",
    "df_produ[2]=df_produ['Receita']\n",
    "df_produ[1]=df_produ['Lucro/Prejuízo do Período']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94532911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provisorio=df_produ\n",
    "df_provisorio=df_provisorio[['Nome Empresa',\n",
    "                             'Ticker',\n",
    "                             'SETOR_ATIV',\n",
    "                             'Flag1Company',\n",
    "                             'DT_REFER',\n",
    "                             'Ano',\n",
    "                             'Mes',\n",
    "                             1,2,3,4,5,6,7,8,9,10,11]]\n",
    "\n",
    "#pego a lista de empresas para analisar\n",
    "LitsofTickers=df_provisorio.drop_duplicates(subset='Ticker')\n",
    "LitsofTickers=LitsofTickers['Ticker'].values\n",
    "for x in LitsofTickers:\n",
    "    DF_Poly=df_provisorio[df_provisorio['Ticker']==x].reset_index(drop=True)\n",
    "    DF_Poly.sort_values(by=['DT_REFER']).reset_index(drop=True)\n",
    "    #transformo os indexes em variáveis e a data em datetime\n",
    "    DF_Poly[\"indexes\"]=DF_Poly.index\n",
    "    DF_Poly['DT_REFER']=pd.to_datetime(DF_Poly['DT_REFER'])\n",
    "    #pego a ultima linha dessa empresa para pegar as informações principais para criar um novo dataset\n",
    "    Lastmonth=DF_Poly.iloc[-1]['DT_REFER']\n",
    "    Lastname=DF_Poly.iloc[-1]['Nome Empresa']\n",
    "    Lastsector=DF_Poly.iloc[-1]['SETOR_ATIV']\n",
    "    Lastnamesub=DF_Poly.iloc[-1]['Ticker']\n",
    "    Lastindex=DF_Poly.iloc[-1]['indexes']\n",
    "    #Crio as datas que eu quero ver la na frente,baseado na data do ultimo balanço\n",
    "    Lastmonth1=Lastmonth+ relativedelta(months=+3)\n",
    "    Lastmonth2=Lastmonth+ relativedelta(months=+6)\n",
    "    Lastmonth3=Lastmonth+ relativedelta(months=+9)\n",
    "    Lastmonth4=Lastmonth+ relativedelta(months=+12)\n",
    "    #Crio um dataframe novo com essas datas\n",
    "    Dateto=pd.DataFrame({'Data_REF': [Lastmonth1,Lastmonth2,Lastmonth3,Lastmonth4]})\n",
    "    X_seq=pd.DataFrame({'x': [Lastindex+1,Lastindex+2,Lastindex+3,Lastindex+4]})\n",
    "    #Configuro o modelo polimonial\n",
    "    polyreg=make_pipeline(PolynomialFeatures(3),LinearRegression())\n",
    "    Pred=Dateto\n",
    "    Pred[\"Nome Empresa\"]=Lastname\n",
    "    Pred['Ticker']=Lastnamesub\n",
    "    Pred['SETOR_ATIV']=Lastsector\n",
    "    #Leio o historico de todos os indicadores e faço a previsão\n",
    "    for y in range(1,12):\n",
    "        yy=DF_Poly[['indexes']]\n",
    "        xx=DF_Poly[[y]]\n",
    "        polyreg.fit(yy,xx)\n",
    "        Pred2=polyreg.predict(X_seq)\n",
    "        Pred2=pd.DataFrame(Pred2,columns=[y])\n",
    "        Pred[y]=Pred2\n",
    "    DF_Polyline=pd.concat([Pred,DF_Polyline]).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "DF_Polyline['Ano']=DF_Polyline['Data_REF'].apply(str).str[0:4]\n",
    "DF_Polyline['Mes']=DF_Polyline['Data_REF'].apply(str).str[5:7]\n",
    "DF_Polyline['Dados']=\"Previsão\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71db0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753201d8",
   "metadata": {},
   "source": [
    "# Previsão de dividendos + cuspir json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a6ff865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dividendos=pd.read_csv(fr\"Cuspidão\\cuspidor_div.csv\",decimal=',',sep=';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f34967b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tick=dividendos['tick'].drop_duplicates()\n",
    "\n",
    "for name in tick:\n",
    "    #faço os tratame\n",
    "    DF_Polyline=pd.DataFrame()\n",
    "    DF_Poly=dividendos[dividendos['tick']==name].reset_index(drop=True)\n",
    "\n",
    "    DF_Poly['Valor pago']=DF_Poly['Valor pago']/DF_Poly['Qauntidade de Ações']\n",
    "    DF_Poly['Data']=pd.to_datetime(DF_Poly['Data'])\n",
    "    DF_Poly=DF_Poly.drop(columns=['Data de pagamento','Qauntidade de Ações'])\n",
    "\n",
    "    #agrupo as informações em trimestres\n",
    "    DF_Poly_trimestre = DF_Poly.resample('Q', on='Data').sum()\n",
    "\n",
    "    DF_Poly_trimestre['data']=DF_Poly_trimestre.index\n",
    "    DF_Poly_trimestre=DF_Poly_trimestre.reset_index(drop=True)\n",
    "    DF_Poly_trimestre=DF_Poly_trimestre.sort_values(by=['data']).reset_index(drop=True)\n",
    "    DF_Poly_trimestre[\"indexes\"]=DF_Poly_trimestre.index\n",
    "    DF_Poly_trimestre['tipo']=DF_Poly['tick'].str.slice(4, 5)[0]\n",
    "    Lastmonth=DF_Poly_trimestre.iloc[-1]['data']\n",
    "    Lasttype=DF_Poly_trimestre.iloc[-1]['tipo']\n",
    "    Lastindex=DF_Poly_trimestre.iloc[-1]['indexes']\n",
    "\n",
    "    Lastmonth1=Lastmonth+ relativedelta(months=+3)\n",
    "    Lastmonth2=Lastmonth+ relativedelta(months=+6)\n",
    "    Lastmonth3=Lastmonth+ relativedelta(months=+9)\n",
    "    Lastmonth4=Lastmonth+ relativedelta(months=+12)\n",
    "    Lastmonth5=Lastmonth+ relativedelta(months=+15)\n",
    "    Lastmonth6=Lastmonth+ relativedelta(months=+18)\n",
    "    Lastmonth7=Lastmonth+ relativedelta(months=+21)\n",
    "\n",
    "     #Crio um dataframe novo com essas datas\n",
    "    Dateto=pd.DataFrame({'data': [Lastmonth1,Lastmonth2,Lastmonth3,Lastmonth4,Lastmonth5,Lastmonth6,Lastmonth7]})\n",
    "    X_seq=pd.DataFrame({'x': [Lastindex+1,Lastindex+2,Lastindex+3,Lastindex+4,Lastindex+5,Lastindex+6,Lastindex+7]})\n",
    "    #Configuro o modelo polimonial\n",
    "    polyreg=make_pipeline(PolynomialFeatures(3),LinearRegression())\n",
    "    Pred=Dateto\n",
    "    Pred['tipo']=Lasttype\n",
    "    #Leio o historico de todos os indicadores e faço a previsão\n",
    "\n",
    "    yy=DF_Poly_trimestre[['indexes']]\n",
    "    xx=DF_Poly_trimestre['Valor pago']\n",
    "    polyreg.fit(yy,xx)\n",
    "    Pred2=polyreg.predict(X_seq)\n",
    "    Pred2=pd.DataFrame(Pred2,columns=['Valor pago'])\n",
    "    Pred['Valor pago']=Pred2\n",
    "\n",
    "    DF_Polyline=pd.concat([Pred,DF_Polyline]).reset_index(drop=True)\n",
    "    DF_Polyline['info']=\"prev\"\n",
    "\n",
    "    DF_Poly_trimestre=DF_Poly_trimestre.drop(columns=['indexes'])\n",
    "    DF_Poly_trimestre[\"info\"]=\"real\"\n",
    "    DF_Poly_trimestre[['data','tipo','Valor pago','info']]\n",
    "    DF_Poly_trimestre=DF_Poly_trimestre.append(DF_Polyline).reset_index(drop=True)\n",
    "    DF_Poly_trimestre=DF_Poly_trimestre.sort_values(by=['data']).reset_index(drop=True)\n",
    "    DF_Poly_trimestre[\"index\"]=DF_Poly_trimestre.index\n",
    "    DF_Poly_trimestre['period']='tri'\n",
    "    DF_Poly_trimestre=DF_Poly_trimestre.rename(columns={\"Valor pago\": \"valor\"})\n",
    "    DF_Poly_trimestre[['tipo','info','period','valor','data','index']]\n",
    "    DF_Poly_trimestre['data']=pd.to_datetime(DF_Poly_trimestre['data']).dt.date\n",
    "    DF_Poly_trimestre['data']=DF_Poly_trimestre['data'].apply(str)\n",
    "    dados = DF_Poly_trimestre.to_dict('records')\n",
    "    with open(f'pipeline/Empresas_data/{name[:4]}_dividends.json', 'w', encoding='utf-8') as arquivo:\n",
    "            json.dump(dados, arquivo, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b6ef5",
   "metadata": {},
   "source": [
    "# Organizar os dados para cuspir no Front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "934c0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_kmeans=DF_kmeans.fillna(0)\n",
    "#Separo as colunas principais do dataset Kmeans e dou um replace nas clusterizações para criar uma nota\n",
    "DF_kmeans_2=DF_kmeans.loc[:,('Ticker','DT_REFER',\"Dados\",'12 Cluster',\n",
    "            '34 Cluster',\n",
    "            '56 Cluster',\n",
    "            '78 Cluster',\n",
    "            '910 Cluster',\n",
    "            '1112 Cluster',\n",
    "            '1314 Cluster')].replace([0,1,2],[0,10,5])\n",
    "#Crio a nota da empresa baseada nos clusters (0 é ruim, 1 é bom e 2 é mediano)\n",
    "DF_kmeans_2['Nota da Empresa']=DF_kmeans_2['12 Cluster']+DF_kmeans_2['34 Cluster']+DF_kmeans_2['56 Cluster']+DF_kmeans_2['78 Cluster']+DF_kmeans_2['910 Cluster']+DF_kmeans_2['1112 Cluster']+DF_kmeans_2['1314 Cluster']\n",
    "DF_kmeans_2['Nota da Empresa']=DF_kmeans_2['Nota da Empresa']/7\n",
    "DF_kmeans_2['Desempenho do Trimestre']=np.where(DF_kmeans_2['Nota da Empresa']<5,\"Ruim\",\n",
    "                                        (np.where((DF_kmeans_2['Nota da Empresa']>=5) & (DF_kmeans_2['Nota da Empresa']<7) ,\"Médio\",\"Bom\")))\n",
    "#Pego o indicador com a melhor nota de clusterização (indicador denominador)\n",
    "DF_kmeans_2['Melhor Indicador1']=(DF_kmeans_2['12 Cluster']+DF_kmeans_2['34 Cluster']+DF_kmeans_2['56 Cluster'])/3\n",
    "DF_kmeans_2['Melhor Indicador2']=(DF_kmeans_2['34 Cluster']+DF_kmeans_2['78 Cluster']+DF_kmeans_2['910 Cluster']+DF_kmeans_2['1112 Cluster']+DF_kmeans_2['1314 Cluster'])/5\n",
    "DF_kmeans_2['Melhor Indicador']=np.where(DF_kmeans_2['Melhor Indicador1']>DF_kmeans_2['Melhor Indicador2'],\"Receita\",\n",
    "                                        (np.where(DF_kmeans_2['Melhor Indicador1']<DF_kmeans_2['Melhor Indicador2'],\"Patrimônio Líquido\",\"Nenhum\")))\n",
    "df_produ=df1\n",
    "#Pego as colunas antigas sem tratamento de clips\n",
    "DF_kmeans_2 = pd.merge(df_produ,DF_kmeans_2 ,left_on=['Ticker','DT_REFER'], right_on=['Ticker','DT_REFER'])\n",
    "DF_kmeans_2['Analise']=DF_kmeans_2['Flag1Company'].replace([0,1],[\"Analise por Setor\",'Analise com outras empresas'])\n",
    "DF_kmeans_2['Tipo de Analise']='Kmeans'\n",
    "#Deixo tudo limpinho e arrumado no dataset kmeans\n",
    "DF_kmeans_2=DF_kmeans_2[['Nome Empresa','Ticker','SETOR_ATIV','Dados','Analise','Tipo de Analise','Melhor Indicador','Desempenho do Trimestre','DT_REFER','Lucro/Prejuízo do Período','Ativo Total','Ativo Circulante','Contas a Receber','Passivo Total','Passivo Circulante','Obrigações Sociais e Trabalhistas','Obrigações Fiscais','Reservas de Lucro','Patrimônio Líquido','Receita']]\n",
    "#Dou nome aos bois no dataset do polimonial\n",
    "DF_Polyline_2=DF_Polyline.rename({'Data_REF': 'DT_REFER', \n",
    "                                  1: 'Lucro/Prejuízo do Período',\n",
    "                                  2: 'Receita', \n",
    "                                  3: 'Patrimônio Líquido', \n",
    "                                  4: 'Reservas de Lucro', \n",
    "                                  5: 'Ativo Total',\n",
    "                                  6: 'Passivo Total', \n",
    "                                  7: 'Passivo Circulante', \n",
    "                                  8: 'Ativo Circulante',\n",
    "                                  9: 'Contas a Receber',\n",
    "                                  10: 'Obrigações Sociais e Trabalhistas',\n",
    "                                  11: 'Obrigações Fiscais',\n",
    "                                 }, axis=1)\n",
    "#Seto as mesmas colunas do kmeans\n",
    "DF_Polyline_2['Melhor Indicador']='Não Analisado'\n",
    "DF_Polyline_2['Desempenho do Trimestre']='Não Analisado'\n",
    "DF_Polyline_2['Nota da Empresa']='Não Analisado'\n",
    "DF_Polyline_2['Analise']='Analise de Historico Financeiro'\n",
    "DF_Polyline_2['Tipo de Analise']='Regressão Polimonial'\n",
    "#Deixo tudo limpinho e arrumado no dataset polimonial\n",
    "DF_Polyline_2=DF_Polyline_2[['Nome Empresa','Ticker','SETOR_ATIV','Dados','Analise','Tipo de Analise','Melhor Indicador','Desempenho do Trimestre','DT_REFER','Lucro/Prejuízo do Período','Ativo Total','Ativo Circulante','Contas a Receber','Passivo Total','Passivo Circulante','Obrigações Sociais e Trabalhistas','Obrigações Fiscais','Reservas de Lucro','Patrimônio Líquido','Receita']]\n",
    "#Deipois junto tudo e cuspo\n",
    "Base_Unica=pd.concat([DF_Polyline_2,DF_kmeans_2]).reset_index(drop=True)\n",
    "Base_Unica.to_csv(rf\"Cuspidão\\Base_Unica.csv\",decimal=',',sep=';', encoding='latin-1',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccd095",
   "metadata": {},
   "source": [
    "# Código do vitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ec7d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6876e325",
   "metadata": {},
   "source": [
    "# Cruzar bases e ter uma base unica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d6692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8244e1f",
   "metadata": {},
   "source": [
    "# PIPELINE CUSPIDOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cbc7fd",
   "metadata": {},
   "source": [
    "# Ajustando setor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "cd261fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ef68bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "setor_agrup=pd.read_csv(fr\"Depara\\setor_ajust.csv\",delimiter=';',encoding=\"utf-8\",decimal='.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0cdb1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precisa multiplicar os valores da empresa\n",
    "#Base_Unica['Patrimônio Líquido']=Base_Unica['Patrimônio Líquido']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "49a0e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Unica_json = pd.merge( Base_Unica, setor_agrup, left_on='SETOR_ATIV', right_on='SETOR_ASIS')\n",
    "Base_Unica_json = Base_Unica_json.drop(columns=['SETOR_ATIV','SETOR_ASIS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a93aa",
   "metadata": {},
   "source": [
    "# criar arquivo unico de leitura dos cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "640940e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Unica_CARDS_JSON=Base_Unica_json[Base_Unica_json['Dados']=='Realizado'].reset_index(drop=True)\n",
    "Base_Unica_CARDS_JSON = Base_Unica_CARDS_JSON.groupby(['Ticker','Nome Empresa','Patrimônio Líquido','SETOR_AJUST','Desempenho do Trimestre'])['DT_REFER'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b8239a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria a coluna PL do card\n",
    "def formatar_valor(valor):\n",
    "    if valor >= 1000000000:  # Valor em bilhões\n",
    "        valor_dividido = valor / 1000000000\n",
    "        return f'{round(valor_dividido,2):.2f} BI'\n",
    "    \n",
    "    elif valor >= 1000000:  # Valor em milhões\n",
    "        valor_dividido = valor / 1000000\n",
    "        return f'{round(valor_dividido,2):.2f} MM'\n",
    "    \n",
    "    elif valor >= 1000: # Valor menor que 1 milhão\n",
    "        valor_dividido = valor / 1000\n",
    "        return f'{round(valor_dividido,2):.2f} Mil'\n",
    "    \n",
    "    elif valor < 1000 and valor > -1000000: # Valor menor que 1 milhão\n",
    "        valor_dividido = valor / 1000 \n",
    "        return f'{round(valor_dividido,2):.2f} Mil'\n",
    "    \n",
    "    if valor <= -1000000000:  # Valor em bilhões\n",
    "        valor_dividido = valor / 1000000000\n",
    "        return f'{round(valor_dividido,2):.2f} BI'\n",
    "    \n",
    "    elif valor <= -1000000:  # Valor em milhões\n",
    "        valor_dividido = valor / 1000000\n",
    "        return f'{round(valor_dividido,2):.2f} MM'\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "34b458c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Unica_CARDS_JSON['PL'] = Base_Unica_CARDS_JSON ['Patrimônio Líquido'].apply(formatar_valor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "72371201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria a coluna symbol, PM, gain e CMP\n",
    "#coluna PM depende do Preço médio\n",
    "#coluna symbol:down,side e up\n",
    "#coluna CMP: YoY e MoM\n",
    "\n",
    "Base_Unica_CARDS_JSON['symbol'] = \"side\"\n",
    "Base_Unica_CARDS_JSON['PM'] = \"0.0\"\n",
    "Base_Unica_CARDS_JSON['gain'] = \"0%\"\n",
    "Base_Unica_CARDS_JSON['CMP'] = \"YoY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0b06e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria a coluna color\n",
    "\n",
    "def map_desempenho(valor):\n",
    "    if valor == 'Bom':\n",
    "        return 'green'\n",
    "    elif valor == 'Médio':\n",
    "        return 'orange'\n",
    "    elif valor == 'Ruim':\n",
    "        return 'red'\n",
    "    else:\n",
    "        return valor\n",
    "\n",
    "Base_Unica_CARDS_JSON['Desempenho do Trimestre'] = Base_Unica_CARDS_JSON['Desempenho do Trimestre'].apply(map_desempenho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "d31be6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#faz os ajustes finais\n",
    "Base_Unica_CARDS_JSON = Base_Unica_CARDS_JSON.rename(columns={'Ticker':'tick',\n",
    "                                                              'Nome Empresa':'nome',\n",
    "                                                             'SETOR_AJUST':'sector',\n",
    "                                                             'Desempenho do Trimestre':'color'\n",
    "                                                             })\n",
    "Base_Unica_CARDS_JSON=Base_Unica_CARDS_JSON.drop(columns=['Patrimônio Líquido','DT_REFER'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5aa437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "e1dacc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extrai a parte específica da string usando uma expressão regular\n",
    "Base_Unica_CARDS_JSON['nome'] = Base_Unica_CARDS_JSON['nome'].str.replace(' - EM RECUPERAÇÃO JUDICIAL', '')\n",
    "Base_Unica_CARDS_JSON['nome'] = Base_Unica_CARDS_JSON['nome'].str.replace('S.A.', '')\n",
    "Base_Unica_CARDS_JSON['nome'] = Base_Unica_CARDS_JSON['nome'].str.replace('SA.', '')\n",
    "Base_Unica_CARDS_JSON['nome'] = Base_Unica_CARDS_JSON['nome'].str.replace('S/A.', '')\n",
    "Base_Unica_CARDS_JSON['nome'] = Base_Unica_CARDS_JSON['nome'].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b16a9",
   "metadata": {},
   "source": [
    "# Salva os Jsons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "b786b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converta o DataFrame selecionado em uma lista de dicionários\n",
    "dados = Base_Unica_CARDS_JSON.to_dict('records')\n",
    "\n",
    "# Salve os dados como um arquivo JSON\n",
    "\n",
    "with open('pipeline/cards_main.json', 'w', encoding='utf-8') as arquivo:\n",
    "    json.dump(dados, arquivo, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196a085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181954a4",
   "metadata": {},
   "source": [
    "# Pipeline tela unica empresa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdb025",
   "metadata": {},
   "source": [
    "### cuspir informações de finanças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c0c12ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_company=pd.read_csv(fr\"Cuspidão\\cuspidor_inf.csv\",delimiter=';',encoding=\"latin-1\",decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "01719eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_company['tick_resume']=inf_company['tick'].str.slice(0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ea9834ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickador=inf_company['tick_resume'].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "for x in tickador:\n",
    "    data=inf_company[inf_company['tick_resume']==x]\n",
    "    \n",
    "    #Pego o PL médio\n",
    "    PL=data[data['Info']=='P/L']\n",
    "    PL=PL['Data'].str.replace('.', '').str.replace(',', '.')\n",
    "    PL=pd.to_numeric(PL).mean()\n",
    "    \n",
    "    #Pego o DivYield\n",
    "    divyield=data[data['Info']=='Div. Yield']\n",
    "    divyield=divyield['Data'].str.replace('.', '').str.replace(',', '.').str.replace('%', '')\n",
    "    divyield=pd.to_numeric(divyield).mean()\n",
    "    \n",
    "    #Pego o ROE\n",
    "    ROE=data[data['Info']=='ROE']\n",
    "    ROE=ROE['Data'].str.replace('.', '').str.replace(',', '.').str.replace('%', '')\n",
    "    ROE=pd.to_numeric(ROE).mean()\n",
    "    \n",
    "    #Pego a cresc.receita\n",
    "    CR5=data[data['Info']=='Cres. Rec (5a)']\n",
    "    CR5=CR5['Data'].str.replace('.', '').str.replace(',', '.').str.replace('%', '')\n",
    "    CR5=pd.to_numeric(CR5).mean()\n",
    "    \n",
    "    #Pego a LPA\n",
    "    LPA=data[data['Info']=='LPA']\n",
    "    LPA=LPA['Data'].str.replace('.', '').str.replace(',', '.')\n",
    "    LPA=pd.to_numeric(LPA).mean()\n",
    "    \n",
    "    #Pego a Lucro.Liq\n",
    "    LucroLiqu=data[data['Info']=='Relatorio 3 meses Lucro Líquido']\n",
    "    LucroLiqu=LucroLiqu['Data'].str.replace('.', '').str.replace(',', '.')\n",
    "    LucroLiqu=pd.to_numeric(LucroLiqu).mean()\n",
    "    LucroLiqu=formatar_valor(LucroLiqu)\n",
    "    \n",
    "    #Pego a Lucro.Liq\n",
    "    Valormercado=data[data['Info']=='Valor de mercado']\n",
    "    Valormercado=Valormercado['Data'].str.replace('.', '').str.replace(',', '.')\n",
    "    Valormercado=pd.to_numeric(Valormercado).mean()\n",
    "    Valormercado=formatar_valor(Valormercado)\n",
    "    \n",
    "    \n",
    "    #Pego a data ulti.balan\n",
    "    UBL=data[data['Info']=='Últ balanço processado']\n",
    "    UBL=UBL['Data']\n",
    "    # Faz o parsing da data no formato \"01/01/2023\"\n",
    "    UBL= datetime.strptime(UBL.iloc[0], '%d/%m/%Y')   \n",
    "    # Formata a data no formato \"Jan-23\"\n",
    "    UBL = UBL.strftime('%b-%y')\n",
    "\n",
    "    #Pego a MENOR COTAÇÃO\n",
    "    MIN=data[data['Info']=='Min 52 sem']\n",
    "    MIN=MIN['Data'].str.replace('.', '').str.replace(',', '.')\n",
    "    MIN=pd.to_numeric(MIN).mean()\n",
    "    \n",
    "    #Pego a MAIOR COTAÇÃO\n",
    "    MAX=data[data['Info']=='Max 52 sem']\n",
    "    MAX=MAX['Data'].str.replace('.', '').str.replace(',', '.')\n",
    "    MAX=pd.to_numeric(MAX).mean()\n",
    "\n",
    "    new_row = pd.DataFrame({\"tick\": x, \n",
    "                            \"DY\":f\"{round(divyield,2)}%\", \n",
    "                            \"PL\":f\"{round(PL,2)}\",\n",
    "                            \"ROE\":f\"{round(ROE, 2)}%\",\n",
    "                            \"CR5\":f\"{round(CR5,2)}%\",\n",
    "                            \"LPA\":f\"{round(LPA,2)}\",\n",
    "                            \"LucroLiqu\":LucroLiqu,\n",
    "                            \"Valormercado\":Valormercado,\n",
    "                            \"UBL\":UBL,\n",
    "                            \"MIN\":f\"{round(MIN,2)}\",\n",
    "                            \"MAX\":f\"{round(MAX,2)}\"}, index=[0])\n",
    "    # Converta o DataFrame selecionado em uma lista de dicionários\n",
    "    dados = new_row.to_dict('records')\n",
    "\n",
    "    # Salve os dados como um arquivo JSON\n",
    "\n",
    "    with open(f'pipeline/Empresas_data/{x}_fundamentalist.json', 'w', encoding='utf-8') as arquivo:\n",
    "        json.dump(dados, arquivo, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fddb89",
   "metadata": {},
   "source": [
    "### cuspir informações de finanças para o chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1b79f",
   "metadata": {},
   "source": [
    "# Informações previsão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "37a024d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Unica_financas_JSON=Base_Unica_json[Base_Unica_json['Tipo de Analise']=='Regressão Polimonial'].reset_index(drop=True)\n",
    "Base_Unica_financas_JSON_PL_prev = Base_Unica_financas_JSON.groupby(['Ticker','Patrimônio Líquido',\n",
    "'Lucro/Prejuízo do Período',\n",
    "'Receita',\n",
    "'Passivo Total',\n",
    "'Contas a Receber',\n",
    "'Obrigações Sociais e Trabalhistas',\n",
    "'Reservas de Lucro'])['DT_REFER'].max().reset_index()\n",
    "Base_Unica_financas_JSON_PL_prev['info']='prev'\n",
    "Base_Unica_financas_JSON_PL_prev['period']='tri'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b532c",
   "metadata": {},
   "source": [
    "# Informações realizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "21694df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"Cuspidão\\Completao.csv\",delimiter=';',encoding=\"latin-1\",decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "998a7009",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Unica_financas_JSON_PL_real = df.groupby(['Ticker','Patrimônio Líquido',\n",
    "'Lucro/Prejuízo do Período',\n",
    "'Receita',\n",
    "'Passivo Total',\n",
    "'Contas a Receber',\n",
    "'Obrigações Sociais e Trabalhistas',\n",
    "'Reservas de Lucro'])['DT_REFER'].max().reset_index()\n",
    "Base_Unica_financas_JSON_PL_real['info']='real'\n",
    "Base_Unica_financas_JSON_PL_real['period']='tri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "13a61867",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_company_indicators=Base_Unica_financas_JSON_PL_prev.append(Base_Unica_financas_JSON_PL_real).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "503e0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators=['Patrimônio Líquido',\n",
    "'Lucro/Prejuízo do Período',\n",
    "'Receita',\n",
    "'Passivo Total',\n",
    "'Contas a Receber',\n",
    "'Obrigações Sociais e Trabalhistas',\n",
    "'Reservas de Lucro']\n",
    "tick=Base_Unica_financas_JSON_PL_prev['Ticker'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab0ab2",
   "metadata": {},
   "source": [
    "# Cuspidor de indicadores - dividendos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "8c82bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in indicators:\n",
    "    for y in tick:\n",
    "        #Tratar as informações:\n",
    "        base_company_indicators_cuspidor=base_company_indicators[base_company_indicators['Ticker']==y].reset_index(drop=True)\n",
    "        base_company_indicators_cuspidor['valor']=base_company_indicators_cuspidor[x]\n",
    "        base_company_indicators_cuspidor = base_company_indicators_cuspidor.groupby(['Ticker','info','period','valor'])['DT_REFER'].max().reset_index()\n",
    "        base_company_indicators_cuspidor['DT_REFER']=pd.to_datetime(base_company_indicators_cuspidor['DT_REFER']).dt.date\n",
    "        base_company_indicators_cuspidor=base_company_indicators_cuspidor.sort_values(by=['DT_REFER'], ascending=True).reset_index(drop=True)\n",
    "        base_company_indicators_cuspidor['index']=base_company_indicators_cuspidor.index\n",
    "        base_company_indicators_cuspidor=base_company_indicators_cuspidor.rename(columns={\"Ticker\": \"tick\", \n",
    "                                                                                          \"DT_REFER\": \"data\"})\n",
    "        \n",
    "        base_company_indicators_cuspidor['data']=base_company_indicators_cuspidor['data'].apply(str)\n",
    "        base_company_indicators_cuspidor['valor']=round(base_company_indicators_cuspidor['valor'],2)\n",
    "        #Cuspir json das empresas\n",
    "        dados = base_company_indicators_cuspidor.to_dict('records')\n",
    "        name_file=x.replace('/','_')\n",
    "        name_file=name_file.replace(' ','_')\n",
    "        # Salve os dados como um arquivo JSON\n",
    "        with open(f'pipeline/Empresas_data/{y}_{name_file}.json', 'w', encoding='utf-8') as arquivo:\n",
    "            json.dump(dados, arquivo, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ff436461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tick  info period       valor        data  index\n",
      "0   YDUQ  real    tri   118285.00  2011-03-31      0\n",
      "1   YDUQ  real    tri    99128.00  2011-06-30      1\n",
      "2   YDUQ  real    tri    96016.00  2011-09-30      2\n",
      "3   YDUQ  real    tri   147403.00  2012-06-30      3\n",
      "4   YDUQ  real    tri   142601.00  2012-09-30      4\n",
      "5   YDUQ  real    tri   226237.00  2013-09-30      5\n",
      "6   YDUQ  real    tri   412826.00  2014-06-30      6\n",
      "7   YDUQ  real    tri   412827.00  2014-09-30      7\n",
      "8   YDUQ  real    tri   619056.00  2015-03-31      8\n",
      "9   YDUQ  real    tri   622840.00  2015-09-30      9\n",
      "10  YDUQ  real    tri   972570.00  2016-03-31     10\n",
      "11  YDUQ  real    tri   955336.00  2016-06-30     11\n",
      "12  YDUQ  real    tri   808906.00  2016-09-30     12\n",
      "13  YDUQ  real    tri   669584.00  2017-03-31     13\n",
      "14  YDUQ  real    tri   682036.00  2017-06-30     14\n",
      "15  YDUQ  real    tri   682207.00  2017-09-30     15\n",
      "16  YDUQ  real    tri   958058.00  2018-03-31     16\n",
      "17  YDUQ  real    tri   886873.00  2018-06-30     17\n",
      "18  YDUQ  real    tri   718288.00  2018-09-30     18\n",
      "19  YDUQ  real    tri   812035.00  2019-03-31     19\n",
      "20  YDUQ  real    tri   818583.00  2019-06-30     20\n",
      "21  YDUQ  real    tri   822311.00  2019-09-30     21\n",
      "22  YDUQ  real    tri  1316142.00  2020-03-31     22\n",
      "23  YDUQ  real    tri  1327044.00  2020-06-30     23\n",
      "24  YDUQ  real    tri  1327644.00  2020-09-30     24\n",
      "25  YDUQ  real    tri  1404431.00  2021-03-31     25\n",
      "26  YDUQ  real    tri  1465767.00  2021-09-30     26\n",
      "27  YDUQ  real    tri  1382591.00  2022-03-31     27\n",
      "28  YDUQ  real    tri  1301595.00  2022-06-30     28\n",
      "29  YDUQ  real    tri  1225413.00  2022-09-30     29\n",
      "30  YDUQ  prev    tri  1459898.00  2022-12-30     30\n",
      "31  YDUQ  prev    tri  1493044.13  2023-03-30     31\n",
      "32  YDUQ  prev    tri  1525312.91  2023-06-30     32\n",
      "33  YDUQ  prev    tri  1556662.32  2023-09-30     33\n"
     ]
    }
   ],
   "source": [
    "print(base_company_indicators_cuspidor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47681795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
